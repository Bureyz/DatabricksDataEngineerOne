{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd92457",
   "metadata": {},
   "source": [
    "# Workshop 4: Unity Catalog Governance\n",
    "\n",
    "## The Story\n",
    "\n",
    "A security audit revealed that too many users have access to sensitive customer data.\n",
    "Your task is to secure the `customers_governance` table using Unity Catalog.\n",
    "You need to implement Row-Level Security (RLS) to ensure analysts can only see data from their own country.\n",
    "\n",
    "**Your Mission:**\n",
    "1. Audit current permissions.\n",
    "2. Grant specific permissions to a group.\n",
    "3. Create a Row Filter (RLS) to restrict access.\n",
    "4. Create a Data Mask to hide PII (Personally Identifiable Information).\n",
    "\n",
    "**Time:** 30 minutes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../00_setup\n",
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "# --- INDEPENDENT SETUP ---\n",
    "# We will create a small synthetic table (20 rows) for the workshop.\n",
    "table_name = f\"{CATALOG}.{BRONZE_SCHEMA}.customers_governance\"\n",
    "\n",
    "print(f\"Generating synthetic data for table: {table_name}...\")\n",
    "\n",
    "# Generate 20 unique, realistic records with SSN (Sensitive Data)\n",
    "data = [\n",
    "    (1, \"James\", \"Smith\", \"james.smith@example.com\", \"123-45-6789\", \"US\"),\n",
    "    (2, \"Michael\", \"Johnson\", \"michael.johnson@example.com\", \"234-56-7890\", \"US\"),\n",
    "    (3, \"Robert\", \"Williams\", \"robert.williams@example.com\", \"345-67-8901\", \"US\"),\n",
    "    (4, \"Maria\", \"Jones\", \"maria.jones@example.com\", \"456-78-9012\", \"US\"),\n",
    "    (5, \"David\", \"Brown\", \"david.brown@example.com\", \"567-89-0123\", \"US\"),\n",
    "    (6, \"Joseph\", \"Davis\", \"joseph.davis@example.com\", \"678-90-1234\", \"US\"),\n",
    "    (7, \"Thomas\", \"Miller\", \"thomas.miller@example.com\", \"789-01-2345\", \"US\"),\n",
    "    (8, \"Charles\", \"Wilson\", \"charles.wilson@example.com\", \"890-12-3456\", \"US\"),\n",
    "    (9, \"Daniel\", \"Moore\", \"daniel.moore@example.com\", \"901-23-4567\", \"US\"),\n",
    "    (10, \"Matthew\", \"Taylor\", \"matthew.taylor@example.com\", \"012-34-5678\", \"US\"),\n",
    "    (11, \"Christopher\", \"Anderson\", \"chris.anderson@example.com\", \"321-54-9876\", \"UK\"),\n",
    "    (12, \"Andrew\", \"Thomas\", \"andrew.thomas@example.com\", \"432-65-0987\", \"UK\"),\n",
    "    (13, \"Elizabeth\", \"Jackson\", \"elizabeth.jackson@example.com\", \"543-76-1098\", \"UK\"),\n",
    "    (14, \"Brian\", \"White\", \"brian.white@example.com\", \"654-87-2109\", \"UK\"),\n",
    "    (15, \"George\", \"Harris\", \"george.harris@example.com\", \"765-98-3210\", \"UK\"),\n",
    "    (16, \"Jennifer\", \"Martin\", \"jennifer.martin@example.com\", \"876-09-4321\", \"UK\"),\n",
    "    (17, \"Linda\", \"Thompson\", \"linda.thompson@example.com\", \"987-10-5432\", \"UK\"),\n",
    "    (18, \"Barbara\", \"Garcia\", \"barbara.garcia@example.com\", \"098-21-6543\", \"UK\"),\n",
    "    (19, \"Susan\", \"Martinez\", \"susan.martinez@example.com\", \"109-32-7654\", \"UK\"),\n",
    "    (20, \"Jessica\", \"Robinson\", \"jessica.robinson@example.com\", \"210-43-8765\", \"UK\"),\n",
    "]\n",
    "\n",
    "schema = \"CustomerID INT, FirstName STRING, LastName STRING, Email STRING, SSN STRING, Country STRING\"\n",
    "df_synthetic = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Add FullName\n",
    "df_final = df_synthetic.withColumn(\"FullName\", concat(col(\"FirstName\"), lit(\" \"), col(\"LastName\")))\n",
    "\n",
    "# Save as Delta Table\n",
    "df_final.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"✅ Table {table_name} created successfully with 20 unique records.\")\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb495a4",
   "metadata": {},
   "source": [
    "## Step 1: Audit Permissions\n",
    "\n",
    "### Task 1.1: Check current grants\n",
    "\n",
    "See who has access to the table.\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "SHOW GRANTS ON TABLE catalog.schema.table_name\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3bfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Show grants\n",
    "# display(spark.sql(f\"SHOW GRANTS ON TABLE {table_name}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c0082",
   "metadata": {},
   "source": [
    "## Step 2: Row-Level Security (Row Filter)\n",
    "\n",
    "We want to restrict access so that users can only see rows where `Country = 'US'`.\n",
    "\n",
    "### Task 2.1: Create a Row Filter Function\n",
    "\n",
    "Create a SQL function that returns TRUE if the user is allowed to see the row.\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "CREATE OR REPLACE FUNCTION filter_country(country STRING)\n",
    "RETURN IF(is_account_group_member('admin'), true, country = 'US')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4161e515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create row filter function\n",
    "# spark.sql(f\"CREATE OR REPLACE FUNCTION {CATALOG}.{BRONZE_SCHEMA}.filter_country ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea87a8",
   "metadata": {},
   "source": [
    "### Task 2.2: Apply the Filter to the Table\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "ALTER TABLE catalog.schema.table_name SET ROW FILTER catalog.schema.filter_country ON (Country)\n",
    "```\n",
    "\n",
    "## Step 3: Column Masking (Dynamic Data Masking)\n",
    "\n",
    "We need to hide the `SSN` column for non-admins.\n",
    "\n",
    "### Task 3.1: Create a Masking Function\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "CREATE OR REPLACE FUNCTION mask_ssn(ssn STRING)\n",
    "RETURN CASE WHEN is_account_group_member('admin') THEN ssn ELSE '***-**-****' END\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2653fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply row filter\n",
    "# spark.sql(f\"ALTER TABLE {table_name} SET ROW FILTER ...\")\n",
    "\n",
    "# TODO: Create masking function\n",
    "# spark.sql(f\"CREATE OR REPLACE FUNCTION {CATALOG}.{BRONZE_SCHEMA}.mask_ssn ...\")\n",
    "\n",
    "# TODO: Apply column mask\n",
    "# spark.sql(f\"ALTER TABLE {table_name} ALTER COLUMN SSN SET MASK ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832a4e0",
   "metadata": {},
   "source": [
    "## Step 4: Metadata Management (Tags & Comments)\n",
    "\n",
    "Good governance requires good documentation. Unity Catalog allows you to add **Comments** and **Tags** to tables and columns.\n",
    "\n",
    "### Task 4.1: Add Comments\n",
    "Add a description to the table and the `SSN` column.\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "COMMENT ON TABLE catalog.schema.table IS 'Customer data with PII'\n",
    "COMMENT ON COLUMN catalog.schema.table.column IS 'Social Security Number'\n",
    "```\n",
    "\n",
    "### Task 4.2: Add Tags\n",
    "Tag the table as containing PII data.\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "ALTER TABLE catalog.schema.table SET TAGS ('pii' = 'true', 'sensitivity' = 'high')\n",
    "ALTER TABLE catalog.schema.table ALTER COLUMN SSN SET TAGS ('pii' = 'true')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5377cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add comments\n",
    "# spark.sql(f\"COMMENT ON TABLE {table_name} IS ...\")\n",
    "# spark.sql(f\"COMMENT ON COLUMN {table_name}.SSN IS ...\")\n",
    "\n",
    "# TODO: Add tags\n",
    "# spark.sql(f\"ALTER TABLE {table_name} SET TAGS ...\")\n",
    "# spark.sql(f\"ALTER TABLE {table_name} ALTER COLUMN SSN SET TAGS ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e36889",
   "metadata": {},
   "source": [
    "## Step 5: Data Quality (Constraints)\n",
    "\n",
    "Governance is not just about security, it's also about **Data Quality**.\n",
    "We want to ensure that no one can insert invalid data into our governed table.\n",
    "\n",
    "### Task 5.1: Add a Constraint\n",
    "\n",
    "Add a check constraint to ensure `SSN` is not empty and has at least 5 characters.\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "ALTER TABLE catalog.schema.table_name ADD CONSTRAINT valid_ssn CHECK (length(SSN) > 5)\n",
    "```\n",
    "\n",
    "### Task 5.2: Test the Constraint\n",
    "\n",
    "Try to insert an invalid record and see it fail.\n",
    "\n",
    "**Hint:**\n",
    "```sql\n",
    "INSERT INTO catalog.schema.table_name (CustomerID, SSN) VALUES (999, 'BAD')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bfe838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add constraint\n",
    "# spark.sql(f\"ALTER TABLE {table_name} ADD CONSTRAINT ...\")\n",
    "\n",
    "# TODO: Try to insert invalid data (Expect Error)\n",
    "# try:\n",
    "#     spark.sql(f\"INSERT INTO {table_name} ...\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Caught expected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bd604",
   "metadata": {},
   "source": [
    "## Step 6: Verification\n",
    "\n",
    "Query the table to see if the filter, mask, and constraints are working.\n",
    "(Note: If you are an admin, you might still see everything unless you test with a different user or logic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify results\n",
    "display(spark.table(table_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae71b93",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "The complete code is below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FULL SOLUTION - Workshop 4: Unity Catalog Governance\n",
    "# ============================================================\n",
    "\n",
    "table_name = f\"{CATALOG}.{BRONZE_SCHEMA}.customers_governance\"\n",
    "\n",
    "# --- Step 1: Audit ---\n",
    "print(\"CURRENT GRANTS:\")\n",
    "display(spark.sql(f\"SHOW GRANTS ON TABLE {table_name}\"))\n",
    "\n",
    "# --- Step 2: Row Filter ---\n",
    "# 1. Create Function\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {CATALOG}.{BRONZE_SCHEMA}.filter_country(country STRING)\n",
    "RETURN IF(is_account_group_member('admin'), true, country = 'US')\n",
    "\"\"\")\n",
    "\n",
    "# 2. Apply Filter\n",
    "spark.sql(f\"ALTER TABLE {table_name} SET ROW FILTER {CATALOG}.{BRONZE_SCHEMA}.filter_country ON (Country)\")\n",
    "print(\"Row Filter applied.\")\n",
    "\n",
    "# --- Step 3: Column Mask ---\n",
    "# 1. Create Function\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION {CATALOG}.{BRONZE_SCHEMA}.mask_ssn(ssn STRING)\n",
    "RETURN CASE WHEN is_account_group_member('admin') THEN ssn ELSE '***-**-****' END\n",
    "\"\"\")\n",
    "\n",
    "# 2. Apply Mask\n",
    "spark.sql(f\"ALTER TABLE {table_name} ALTER COLUMN SSN SET MASK {CATALOG}.{BRONZE_SCHEMA}.mask_ssn\")\n",
    "print(\"Column Mask applied.\")\n",
    "\n",
    "# --- Step 4: Metadata Management ---\n",
    "# 1. Add Comments\n",
    "spark.sql(f\"COMMENT ON TABLE {table_name} IS 'Customer data with PII'\")\n",
    "spark.sql(f\"COMMENT ON COLUMN {table_name}.SSN IS 'Social Security Number'\")\n",
    "print(\"Comments added.\")\n",
    "\n",
    "# 2. Add Tags\n",
    "spark.sql(f\"ALTER TABLE {table_name} SET TAGS ('pii' = 'true', 'sensitivity' = 'high')\")\n",
    "spark.sql(f\"ALTER TABLE {table_name} ALTER COLUMN SSN SET TAGS ('pii' = 'true')\")\n",
    "print(\"Tags added.\")\n",
    "\n",
    "# --- Step 5: Data Quality ---\n",
    "try:\n",
    "    spark.sql(f\"ALTER TABLE {table_name} ADD CONSTRAINT valid_ssn CHECK (length(SSN) > 5)\")\n",
    "    print(\"Constraint added.\")\n",
    "except Exception as e:\n",
    "    print(f\"Constraint might already exist: {e}\")\n",
    "\n",
    "print(\"Testing constraint with invalid data...\")\n",
    "try:\n",
    "    spark.sql(f\"INSERT INTO {table_name} (CustomerID, SSN) VALUES (999, 'BAD')\")\n",
    "except Exception as e:\n",
    "    print(\"✅ SUCCESS: Invalid data was rejected by Unity Catalog!\")\n",
    "\n",
    "# --- Step 6: Verification ---\n",
    "print(\"\\nVERIFICATION (As Admin):\")\n",
    "display(spark.table(table_name))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
